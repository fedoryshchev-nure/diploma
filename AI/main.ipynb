{"cells":[{"metadata":{"trusted":false,"_uuid":"78572cfaad5f9c96aa4e55416b3a5906de0c951e"},"cell_type":"code","source":["from IPython.core.interactiveshell import InteractiveShell\n","\n","# Set shell to show all lines of output\n","InteractiveShell.ast_node_interactivity = 'all'\n"],"execution_count":131,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cb43833559ff4a2cc77795ed9306f039eedc0018"},"cell_type":"code","source":["books = [\n","    ['00000000-0000-0000-0000-000000000001', [50, 75, 150, 30, 40, 15]],\n","    ['00000000-0000-0000-0000-000000000002', [15, 20, 100]],\n","    ['00000000-0000-0000-0000-000000000003', [50, 60, 70]],\n","    ['00000000-0000-0000-0000-000000000004', [5, 150, 30, 45, 15]],\n","    ['00000000-0000-0000-0000-000000000005', [40, 15]]\n","]"],"execution_count":132,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bb6d85f58f57e5403468e826a764bfaef20a78a1"},"cell_type":"code","source":["book_index = {book[0]: idx for idx, book in enumerate(books)}\n","index_book = {idx: book for book, idx in book_index.items()}"],"execution_count":133,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"44b0a6e3313ff37d39629bde897c4c422c23ebd4"},"cell_type":"code","source":["from collections import Counter, OrderedDict\n","\n","def count_items(l):\n","    \"\"\"Return ordered dictionary of counts of objects in `l`\"\"\"\n","    \n","    # Create a counter object\n","    counts = Counter(l)\n","    \n","    # Sort by highest count first and place in ordered dictionary\n","    counts = sorted(counts.items(), key = lambda x: x[1], reverse = True)\n","    counts = OrderedDict(counts)\n","    \n","    return counts"],"execution_count":134,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"326e515d0eb9d2b2c78798faa3225dd2fb1cc55d"},"cell_type":"code","source":["from itertools import chain \n","unique_wikilinks = list(chain(*[list(set(book[1])) for book in books]))\n","\n","wikilink_counts = count_items(unique_wikilinks)\n","\n","unique_wikilinks_books = list(chain(*[list(set(link for link in book[1])) for book in books]))\n","# Count the number of books linked to by other books\n","wikilink_book_counts = count_items(unique_wikilinks_books)"],"execution_count":135,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"40a1e6b9e7a77e17721b5ff092d7f6fbb6219692"},"cell_type":"code","source":["wikilinks = unique_wikilinks\n","wikilink_counts = count_items(wikilinks)"],"execution_count":136,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9e9082e9f2a3846488739aee5d74f5cf5cabf936"},"cell_type":"code","source":["# Limit to greater than 3 links\n","links = [t[0] for t in wikilink_counts.items()]"],"execution_count":137,"outputs":[]},{"metadata":{"_uuid":"b13381b92b1f838c7857194035105fd8472b1b7f"},"cell_type":"markdown","source":["#### Most Linked-to Books\n","\n","As a final bit of exploration, let's look at the books that are mentioned the most by other books on Wikipedia. We'll take the set of links for each book so that we don't have multiple counts for books that are linked to by another book more than once. "]},{"metadata":{"trusted":false,"_uuid":"23d89202d24dac576fdfa3aef252b9b7a6b604c3"},"cell_type":"code","source":["unique_wikilinks_books = list(chain(*[list(set(link for link in book[1])) for book in books]))\n","wikilink_book_counts = count_items(unique_wikilinks_books)"],"execution_count":138,"outputs":[]},{"metadata":{"_uuid":"6a9afb8bece32a86e5ca683cbe79653dd89208a5"},"cell_type":"markdown","source":["## Wikilinks to Index\n","\n","As with the books, we need to map the Wikilinks to integers. We'll also create the reverse mapping."]},{"metadata":{"trusted":false,"_uuid":"acc684534675c53a250f420482fbdc9aa80a5170"},"cell_type":"code","source":["link_index = {link: idx for idx, link in enumerate(links)}\n","index_link = {idx: link for link, idx in link_index.items()}"],"execution_count":139,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ff88918004784cd4255a5d94cb34de4e61096b12"},"cell_type":"code","source":["pairs = []\n","\n","# Iterate through each book\n","for book in books:\n","    # Iterate through the links in the book\n","    pairs.extend((book_index[book[0]], link_index[link]) for link in book[1] if link in links)"],"execution_count":140,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d063b874147568c513877dc1ba849bc5a42ce5fb"},"cell_type":"code","source":["pairs_set = set(pairs)"],"execution_count":141,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a0756ca011c3a5a51168973cd9cbf2e8c0922a92"},"cell_type":"code","source":["import numpy as np\n","import random\n","random.seed(100)\n","\n","def generate_batch(pairs, n_positive = 50, negative_ratio = 1.0):\n","    \"\"\"Generate batches of samples for training\"\"\"\n","    batch_size = n_positive * (1 + negative_ratio)\n","    batch = np.zeros((batch_size, 3))\n","    \n","    # This creates a generator\n","    while True:\n","        # randomly choose positive examples\n","        for idx, (book_id, link_id) in enumerate(random.sample(pairs, n_positive)):\n","            batch[idx, :] = (book_id, link_id, 1)\n","\n","        # Increment idx by 1\n","        idx += 1\n","        \n","        # Add negative examples until reach batch size\n","        while idx < batch_size:\n","            \n","            # random selection\n","            random_book = random.randrange(len(books))\n","            random_link = random.randrange(len(links))\n","            \n","            # Check to make sure this is not a positive example\n","            if (random_book, random_link) not in pairs_set:\n","                \n","                # Add to batch and increment index\n","                batch[idx, :] = (random_book, random_link, -1)\n","                idx += 1\n","                \n","        # Make sure to shuffle order\n","        np.random.shuffle(batch)\n","        yield {'book': batch[:, 0], 'link': batch[:, 1]}, batch[:, 2]"],"execution_count":142,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ac6437fc250ffa369e700983034dd10ecb1cd0ad"},"cell_type":"code","source":["from keras.layers import Input, Embedding, Dot, Reshape, Dense\n","from keras.models import Model"],"execution_count":143,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"03f618c3d84bad94afac5acba8f8ccdf81d1c429"},"cell_type":"code","source":["def book_embedding_model(embedding_size = 50, classification = False):\n","    \"\"\"Model to embed books and wikilinks using the functional API.\n","       Trained to discern if a link is present in a article\"\"\"\n","    \n","    # Both inputs are 1-dimensional\n","    book = Input(name = 'book', shape = [1])\n","    link = Input(name = 'link', shape = [1])\n","    \n","    # Embedding the book (shape will be (None, 1, 50))\n","    book_embedding = Embedding(name = 'book_embedding',\n","                               input_dim = len(book_index),\n","                               output_dim = embedding_size)(book)\n","    \n","    # Embedding the link (shape will be (None, 1, 50))\n","    link_embedding = Embedding(name = 'link_embedding',\n","                               input_dim = len(link_index),\n","                               output_dim = embedding_size)(link)\n","    \n","    # Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))\n","    merged = Dot(name = 'dot_product', normalize = True, axes = 2)([book_embedding, link_embedding])\n","    \n","    # Reshape to be a single number (shape will be (None, 1))\n","    merged = Reshape(target_shape = [1])(merged)\n","    \n","    # If classifcation, add extra layer and loss function is binary cross entropy\n","    if classification:\n","        merged = Dense(1, activation = 'sigmoid')(merged)\n","        model = Model(inputs = [book, link], outputs = merged)\n","        model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    # Otherwise loss function is mean squared error\n","    else:\n","        model = Model(inputs = [book, link], outputs = merged)\n","        model.compile(optimizer = 'Adam', loss = 'mse')\n","    \n","    return model\n","\n","# Instantiate model and show parameters\n","model = book_embedding_model()\n","model.summary()"],"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nbook (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nlink (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nbook_embedding (Embedding)      (None, 1, 50)        250         book[0][0]                       \n__________________________________________________________________________________________________\nlink_embedding (Embedding)      (None, 1, 50)        600         link[0][0]                       \n__________________________________________________________________________________________________\ndot_product (Dot)               (None, 1, 1)         0           book_embedding[0][0]             \n                                                                 link_embedding[0][0]             \n__________________________________________________________________________________________________\nreshape_7 (Reshape)             (None, 1)            0           dot_product[0][0]                \n==================================================================================================\nTotal params: 850\nTrainable params: 850\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"}]},{"metadata":{"trusted":false,"_uuid":"28aa85cfac5d079289fbba3607b30ac08b9bb2e8"},"cell_type":"code","source":["n_positive = 1\n","\n","gen = generate_batch(pairs, n_positive, negative_ratio = 2)\n","\n","# Train\n","h = model.fit_generator(gen, epochs = 6, \n","                        steps_per_epoch = len(pairs) // n_positive,\n","                        verbose = 2)"],"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/6\n - 0s - loss: 1.0053\nEpoch 2/6\n - 0s - loss: 0.8345\nEpoch 3/6\n - 0s - loss: 0.6695\nEpoch 4/6\n - 0s - loss: 0.5650\nEpoch 5/6\n - 0s - loss: 0.4440\nEpoch 6/6\n - 0s - loss: 0.4050\n"}]},{"metadata":{"trusted":false,"_uuid":"fa075b8a99b673dc8359d43e9428b5f50b6d35a5"},"cell_type":"code","source":["book_layer = model.get_layer('book_embedding')\n","book_weights = book_layer.get_weights()[0]\n","book_weights = book_weights / np.linalg.norm(book_weights, axis = 1).reshape((-1, 1))\n","np.sum(np.square(book_weights[0]))"],"execution_count":146,"outputs":[{"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{},"execution_count":146}]},{"metadata":{"trusted":false,"_uuid":"a55c6da94ada692a1ef52f376844a2f79a4c69af"},"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def find_similar(name, weights, n = 3):\n","    \"\"\"Find n most similar items (or least) to name based on embeddings. Option to also plot the results\"\"\"\n","\n","    index = book_index\n","    rindex = index_book\n","    \n","    # Check to make sure `name` is in index\n","    try:\n","        # Calculate dot product between book and all others\n","        dists = np.dot(weights, weights[index[name]])\n","    except KeyError:\n","        print(f'{name} Not Found.')\n","        return\n","    \n","    # Sort distance indexes from smallest to largest\n","    sorted_dists = np.argsort(dists)\n","        \n","    closest = sorted_dists[-(n + 1):]\n","\n","    res = [{'courseId': rindex[c], 'similarity': f'{dists[c]:.{2}}'}  for c in reversed(closest) if rindex[c] != name]\n","    return res\n","        \n","    "],"execution_count":156,"outputs":[]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"caa06c23-ddd5-4440-2e02-08d80eb2d339 Not Found.\n"}],"source":["import json\n","REQUEST = json.dumps({ 'path' : { 'courseId': '' } })"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Not Found.\n"},{"output_type":"execute_result","data":{"text/plain":"'null'"},"metadata":{},"execution_count":149}],"source":["# GET /recommendations/:courseId\n","req = json.loads(REQUEST)\n","courseId = req['path']['courseId']\n","\n","recommendations = find_similar(courseId, book_weights)\n","print(json.dumps(recommendations))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# jupyter kernelgateway --api='kernel_gateway.notebook_http' --seed_uri='main.ipynb' --port 9090"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.3 32-bit ('.venv': venv)","language":"python","name":"python38332bitvenvvenvbbc0eef91cc940319ce392848ef41b21"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"}},"nbformat":4,"nbformat_minor":1}